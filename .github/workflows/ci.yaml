name: CI

env:
  IMAGE_NAME: tubesync

on:
  workflow_dispatch:
  push:
    branches:
      - 'main'
      - 'test-*'
  pull_request:
    branches:
      - 'main'
      - 'test-*'
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review

jobs:
  info:
    if: ${{ !cancelled() && 'pull_request' != github.event_name }}
    runs-on: ubuntu-latest
    outputs:
      ffmpeg-date: ${{ steps.jq.outputs.FFMPEG_DATE }}
      ffmpeg-releases: ${{ steps.ffmpeg.outputs.releases }}
      ffmpeg-version: ${{ steps.jq.outputs.FFMPEG_VERSION }}
      lowercase-github-actor: ${{ steps.github-actor.outputs.lowercase }}
      lowercase-github-repository_owner: ${{ steps.github-repository_owner.outputs.lowercase }}
      ytdlp-latest-release: ${{ steps.yt-dlp.outputs.latest-release }}
      ytdlp-releases: ${{ steps.yt-dlp.outputs.releases }}
    steps:
      - uses: actions/checkout@v4
      - name: Lowercase github username
        id: github-actor
        uses: ./.github/actions/string-case
        with:
          string: ${{ github.actor }}
      - name: Lowercase github repository owner
        id: github-repository_owner
        uses: ./.github/actions/string-case
        with:
          string: ${{ github.repository_owner }}
      - name: Retrieve yt-dlp/FFmpeg-Builds releases with GitHub CLI
        id: ffmpeg
        uses: ./.github/actions/FFmpeg
      - name: Retrieve yt-dlp/yt-dlp releases with GitHub CLI
        id: yt-dlp
        uses: ./.github/actions/yt-dlp
      - name: Set outputs with jq
        id: jq
        run: |
          cat >| .ffmpeg.releases.json <<'EOF'
          ${{ steps.ffmpeg.outputs.releases }}
          EOF
          mk_delim() { local f='%s_EOF_%d_' ; printf -- "${f}" "$1" "${RANDOM}" ; } ;
          open_ml_var() { local f=''\%'s<<'\%'s\n' ; printf -- "${f}" "$2" "$1" ; } ;
          close_ml_var() { local f='%s\n' ; printf -- "${f}" "$1" ; } ;
          {
            var='FFMPEG_DATE' ;
            delim="$(mk_delim "${var}")" ;
            open_ml_var "${delim}" "${var}" ;
            jq_arg='[foreach .[] as $release ([{}, []]; [ .[0] + {($release.commit): ([ $release.date ] + (.[0][($release.commit)] // []) ) }, [ .[1][0] // $release.commit ] ] ; .[0][(.[1][0])] ) ][-1][0]' ;
            jq -r "${jq_arg}" -- .ffmpeg.releases.json ;
            close_ml_var "${delim}" "${var}" ;

            ffmpeg_date="$( jq -r "${jq_arg}" -- .ffmpeg.releases.json )"
            
            var='FFMPEG_VERSION' ;
            delim="$(mk_delim "${var}")" ;
            open_ml_var "${delim}" "${var}" ;
            jq_arg='.[]|select(.date == $date)|.versions[]|select(startswith("N-"))' ;
            jq -r --arg date "${ffmpeg_date}" "${jq_arg}" -- .ffmpeg.releases.json ;
            close_ml_var "${delim}" "${var}" ;
            unset -v delim jq_arg var ;
          } >> "${GITHUB_OUTPUT}"
          cat -v "${GITHUB_OUTPUT}"
          rm -v -f .ffmpeg.releases.json

  test:
    if: ${{ !cancelled() && ( 'pull_request' != github.event_name || (! github.event.pull_request.draft) ) }}
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12', '3.13']
    steps:
      - uses: actions/checkout@v4
      - name: Install Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install uv
          uv --no-config --no-managed-python --no-progress \
            pip install --system --strict pipenv
          pipenv lock
          pipenv requirements | tee requirements.txt
          #PIPENV_VERBOSITY=64 pipenv install --system --skip-lock
          uv --no-config --no-managed-python --no-progress \
            pip install --system --strict --requirements requirements.txt
      - name: Set up Django environment
        run: |
          cp -v -p tubesync/tubesync/local_settings.py.example tubesync/tubesync/local_settings.py
          cp -v -a -t "${Python3_ROOT_DIR}"/lib/python3.*/site-packages/background_task/ patches/background_task/*
          cp -v -a -t "${Python3_ROOT_DIR}"/lib/python3.*/site-packages/yt_dlp/ patches/yt_dlp/*
          cd tubesync && python3 -B manage.py collectstatic --no-input --link
      - name: Check with ruff
        continue-on-error: false
        run: |
          target_version='py310'
          ignore_csv_list='E701,E722,E731'
          cd tubesync
          # output formats:
          # "full" | "concise" | "grouped" |
          # "json" | "junit" | "github" | "gitlab" |
          # "pylint" | "azure"
          {
              echo '## Output from `ruff check` for `tubesync`'
              echo ''
              echo '### Formats'
              echo ''
              for fmt in full concise grouped pylint
              do
              echo '<details>'
              echo '<summary>'"${fmt}"'</summary>'
              echo ''
              echo '#### '"${fmt}"' output format'
              echo ''
              echo '```'
              uvx --no-config --no-managed-python --no-progress --isolated \
                  ruff check --exit-zero \
                  --target-version "${target_version}" \
                  --output-format "${fmt}" \
                  --extend-select RUF100 \
                  --ignore "${ignore_csv_list}"
              echo ''
              echo '```'
              echo ''
              echo '</details>'
              echo ''
              done
          } >> "${GITHUB_STEP_SUMMARY}"
          uvx --no-config --no-managed-python --no-progress --isolated \
              ruff check \
              --target-version "${target_version}" \
              --output-format github \
              --ignore "${ignore_csv_list}"
      - name: Run Django tests
        run: cd tubesync && python3 -B -W default manage.py test --verbosity=2

  containerise:
    if: ${{ !cancelled() && 'success' == needs.info.result }}
    needs: ['info', 'test']
    runs-on: ubuntu-latest
    timeout-minutes: 120
    services:
      wormhole-mailbox:
        image: 'ghcr.io/tcely/docker-magic-wormhole-mailbox-server:service'
        ports:
          - '4000:4000'
      wormhole-transit:
        image: 'ghcr.io/tcely/docker-magic-wormhole-transit-relay:main'
        ports:
          - '4001:4001'
    steps:
      - name: Set environment variables with jq
        run: |
          # jq
          cat >| .ffmpeg.releases.json <<'EOF'
          ${{ needs.info.outputs.ffmpeg-releases }}
          EOF

          FFMPEG_DATE='[foreach .[] as $release ([{}, []]; [ .[0] + { ($release.commit): ([ $release.date ] + (.[0][($release.commit)] // [])) }, [ .[1][0] // $release.commit ] ] ; .[0][(.[1][0])] )][-1][0]' ;
          FFMPEG_VERSION='.[]|select(.date == $previous)|.versions[]|select(startswith("N-"))' ;

          mk_delim() { printf -- '"%s_EOF_%d_"' "$1" "${RANDOM}" ; } ;
          open_ml_var() { local f=''\%'s<<'\%'s\n' ; printf -- "${f}" "$2" "$1" ; } ;
          close_ml_var() { local f='%s\n' ; printf -- "${f}" "$1" ; } ;
          {
            for var in FFMPEG_DATE FFMPEG_VERSION
            do
              # jq_arg="$( eval printf -- "'%s\n'" "$(printf -- '"${%s}"' "${var}")" )" ;
              jq_arg="$( eval printf -- "'%s\n'" '"${'"${var}"'}"' )" ;
              delim='"'"${var}"'_EOF"' ;
              printf -- '%s<<%s\n' "${var}" "${delim}" ;
              jq -r --arg previous "${previous_value-}" "${jq_arg}" -- .ffmpeg.releases.json ;
              printf -- '%s\n' "${delim}" ;
              previous_value="$( jq -r --arg previous "${previous_value-}" "${jq_arg}" -- .ffmpeg.releases.json )" ;
            done ;

            var='FFMPEG_DATE' ;
            delim="$(mk_delim "${var}")" ;
            open_ml_var "${delim}" "${var}" ;
            jq_arg='[foreach .[] as $release ([{}, []]; [ .[0] + {($release.commit): ([ $release.date ] + (.[0][($release.commit)] // []) ) }, [ .[1][0] // $release.commit ] ] ; .[0][(.[1][0])] ) ][-1][0]' ;
            jq -r "${jq_arg}" -- .ffmpeg.releases.json ;
            close_ml_var "${delim}" "${var}" ;

            ffmpeg_date="$( jq -r "${jq_arg}" -- .ffmpeg.releases.json )"
            
            var='FFMPEG_VERSION' ;
            delim="$(mk_delim "${var}")" ;
            open_ml_var "${delim}" "${var}" ;
            jq_arg='.[]|select(.date == $date)|.versions[]|select(startswith("N-"))' ;
            jq -r --arg date "${ffmpeg_date}" "${jq_arg}" -- .ffmpeg.releases.json ;
            close_ml_var "${delim}" "${var}" ;
  
            unset -v delim jq_arg previous_value var ;
          } >> "${GITHUB_ENV}"
          rm -v -f .ffmpeg.releases.json
      - name: Set environment variables with GitHub CLI
        env:
          GH_REPO: ${{ github.repository }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # gh api
          GH_UPSTREAM_OWNER='.parent.owner.login' ;
          GH_UPSTREAM_REPO='.parent.name' ;
          GH_UPSTREAM_SLUG='.parent.full_name' ;

          mk_delim() { printf -- '"%s_EOF_%d_"' "$1" "${RANDOM}" ; } ;
          open_ml_var() { local f=''\%'s<<'\%'s\n' ; printf -- "${f}" "$2" "$1" ; } ;
          close_ml_var() { local f='%s\n' ; printf -- "${f}" "$1" ; } ;
          {
            for var in GH_UPSTREAM_OWNER # GH_UPSTREAM_REPO GH_UPSTREAM_SLUG
            do
              # jq_arg="$( eval printf -- "'%s\n'" "$(printf -- '"${%s}"' "${var}")" )" ;
              jq_arg="$( eval printf -- "'%s\n'" '"${'"${var}"'}"' )" ;
              delim='"'"${var}"'_EOF"' ;
              printf -- '%s<<%s\n' "${var}" "${delim}" ;
              gh api "repos/${GITHUB_REPOSITORY}" --cache 1h --jq "${jq_arg}" ;
              printf -- '%s\n' "${delim}" ;
            done ;
            unset -v delim jq_arg var ;
          } >> "${GITHUB_ENV}"

          # Delete the oldest unused cache entries
          printf -- '%s\n' 'Deleting unused cache entries' ;
          gh cache list --sort last_accessed_at --order asc --ref "${GITHUB_REF}" | \
            awk '$NF == $(NF-1) {print $1}' | \
            xargs -r -t -n 1 gh cache delete 2>&1 | \
            tee /dev/stderr | wc -l | xargs -n 1 printf -- 'Total deleted: %d\n' ;
      - name: Upstream registry ref
        id: upstream
        run: |
          user_lowercase="$(printf -- '%s\n' "${GH_UPSTREAM_OWNER}" | awk '{print tolower($0);}')" ;
          printf >> "$GITHUB_OUTPUT" -- '%s=ghcr.io/%s/%s:latest\n' \
            ref "${user_lowercase}" "${IMAGE_NAME}" \
            tag "${user_lowercase}" "${IMAGE_NAME}" ;
      - name: Registry ref
        id: origin
        run: |
          user_lowercase="$(printf -- '%s\n' "${GITHUB_ACTOR}" | awk '{print tolower($0);}')" ;
          printf >> "$GITHUB_OUTPUT" -- '%s=ghcr.io/%s/%s:%s\n' \
            'ref' "${user_lowercase}" "${IMAGE_NAME}" 'cache' \
            'tag' "${user_lowercase}" "${IMAGE_NAME}" 'latest' ;
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
      - name: Log into GitHub Container Registry
        env:
          DOCKER_REGISTRY: https://ghcr.io
          DOCKER_USERNAME: ${{ github.actor }}
          DOCKER_TOKEN: ${{ 'meeb' == github.repository_owner && secrets.REGISTRY_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}
        run: echo "${DOCKER_TOKEN}" | docker login --password-stdin --username "${DOCKER_USERNAME}" "${DOCKER_REGISTRY}"
      - name: Checkout
        uses: actions/checkout@v4
      - name: Create cache directory on the runner
        run: |
          mkdir -v -p .cache
          : >> .cache/reset
          mkdir -v .cache/saved .cache/removed .cache/runner
      - name: Cache from tubesync stage
        id: cache
        uses: actions/cache@v4
        with:
          path: |
            .cache/saved
            .cache/runner
          key: docker-cache-tubesync-${{ hashFiles('.cache/reset') }}-${{ hashFiles('*file', '.github/workflows/ci.yaml') }}
          restore-keys: |
            docker-cache-tubesync-${{ hashFiles('.cache/reset') }}-
      - name: List cache directory on the runner
        run: |
          # limited listing when the cache was restored
          ls -al .cache &&
          ls -al .cache/* &&
          ls -al .cache/*/* &&
          ls -al .cache/*/*/* ||
          ls -alR .cache
      - name: Start magic-wormhole services on the runner
        if: ${{ 'true' != steps.cache.outputs.cache-hit }}
        id: wormhole
        run: |
          rm -rf .cache/runner/wormhole
          sudo apt-get install python3-venv
          venv_dir=".cache/runner/${RUNNER_ARCH}/wormhole" &&
              python3 -m venv --upgrade-deps "${venv_dir}" &&
              . "${venv_dir}"/bin/activate || exit
          pip install 'magic-wormhole'
          # determine the runner IP address
          _awk_prog='$0 !~ /scope host/ && "inet" == $1 {split($2, P, "/"); print P[1]; exit;}'
          runner_ip="$( ip addr sh | awk "${_awk_prog}" )"
          # set variables
          relay_arg="ws://${runner_ip}:4000/v1"
          transit_arg="tcp:[${runner_ip}]:4001"
          # generate the code and receive the first transfer
          ( wormhole \
              --appid TubeSync \
              --relay-url "${relay_arg}" \
              --transit-helper "${transit_arg}" \
              receive -a -c 3 \
              --accept-file -o .cache/incoming >| .cache/receive.out 2>&1 && \
              mv --backup=numbered -f .cache/incoming/* .cache/saved/ || : ; \
              mv --backup=numbered -f .cache/saved/*.~[0-9]~ .cache/removed/ || : ; ) &
          _pid=$!; sleep 1 && grep -e '^Allocated code:' .cache/receive.out | cut -d ' ' -f 3- >| .cache/.wormhole-code
          cat -v -n .cache/receive.out
          rm -v -f .cache/receive.out
          code="$(< .cache/.wormhole-code)"
          rm -v -f .cache/.wormhole-code
          # create output variables
          printf -- '%s=%s\n' >> "$GITHUB_OUTPUT" \
              code "${code}" \
              relay "${relay_arg}" \
              runner_ip "${runner_ip}" \
              transit "${transit_arg}" ;
          # receive the saved directories
          ( cd .cache &&
              while test -d /proc/"${_pid}" ; do sleep 5 ; done &&
              while { \
                wormhole \
                  --appid TubeSync \
                  --relay-url "${relay_arg}" \
                  --transit-helper "${transit_arg}" \
                  receive \
                  --accept-file -o incoming "${code}" || : ; \
              }
              do
                  mv --backup=numbered -f incoming/* saved/ || : ;
                  mv --backup=numbered -f saved/*.~[0-9]~ removed/ || : ;
                  rm -rf removed/* || : ;
              done &)
      - name: Build image for `dive`
        id: build-dive-image
        uses: docker/build-push-action@v6
        with:
          build-args: |
            CI=${{ env.CI }}
            IMAGE_NAME=${{ env.IMAGE_NAME }}
            FFMPEG_DATE=${{ needs.info.outputs.ffmpeg-date }}
            FFMPEG_VERSION=${{ needs.info.outputs.ffmpeg-version }}
            YTDLP_DATE=${{ fromJSON(needs.info.outputs.ytdlp-latest-release).tag.name }}
            WORMHOLE_RELAY=${{ env.WORMHOLE_RELAY }}
            WORMHOLE_TRANSIT=${{ env.WORMHOLE_TRANSIT }}
          build-contexts: |
            cache-tubesync=.cache/saved
          cache-from: type=gha
          load: true
          platforms: linux/amd64
          push: false
          tags: ghcr.io/${{ needs.info.outputs.lowercase-github-actor }}/${{ env.IMAGE_NAME }}:dive
      - name: Analysis with `dive`
        continue-on-error: false
        run: |
          docker run --rm \
            -v /var/run/docker.sock:/var/run/docker.sock \
            'ghcr.io/wagoodman/dive' \
            'ghcr.io/${{ needs.info.outputs.lowercase-github-actor }}/${{ env.IMAGE_NAME }}:dive' \
            --ci \
            --highestUserWastedPercent '0.05' \
            --highestWastedBytes '50M'
      - name: Build and push
        id: build-push
        timeout-minutes: 90
        uses: docker/build-push-action@v6
        env:
          WORMHOLE_CODE: ${{ steps.wormhole.outputs.code }}
          WORMHOLE_RELAY: ${{ steps.wormhole.outputs.relay }}
          WORMHOLE_TRANSIT: ${{ steps.wormhole.outputs.transit }}
        with:
          platforms: linux/amd64,linux/arm64
          push: ${{ 'success' == needs.test.result && 'pull_request' != github.event_name && 'true' || 'false' }}
          provenance: false
          tags: ${{ steps.origin.outputs.tag }}
          cache-from: |
            type=gha
            type=registry,ref=${{ steps.origin.outputs.ref }}
            type=registry,ref=${{ steps.upstream.outputs.ref }}
          cache-to: |
            type=gha,mode=max
          build-args: |
            CI=${{ env.CI }}
            IMAGE_NAME=${{ env.IMAGE_NAME }}
            FFMPEG_DATE=${{ needs.info.outputs.ffmpeg-date }}
            FFMPEG_VERSION=${{ needs.info.outputs.ffmpeg-version }}
            YTDLP_DATE=${{ fromJSON(needs.info.outputs.ytdlp-latest-release).tag.name }}
            WORMHOLE_RELAY=${{ env.WORMHOLE_RELAY }}
            WORMHOLE_TRANSIT=${{ env.WORMHOLE_TRANSIT }}
          build-contexts: |
            cache-tubesync=.cache/saved
          secret-envs: |
            WORMHOLE_CODE=WORMHOLE_CODE
            WORMHOLE_RELAY=WORMHOLE_RELAY
            WORMHOLE_TRANSIT=WORMHOLE_TRANSIT
